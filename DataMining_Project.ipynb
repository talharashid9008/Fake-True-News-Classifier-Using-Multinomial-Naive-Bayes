{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "import yake\n",
    "from yake import KeywordExtractor\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two datasets\n",
    "fake_df = pd.read_csv('Fake.csv')\n",
    "true_df = pd.read_csv('True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>[donald, trump, just, couldn, t, wish, all, am...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>[house, intelligence, committee, chairman, dev...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>[on, friday, it, was, revealed, that, former, ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>[on, christmas, day, donald, trump, announced,...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>[pope, francis, used, his, annual, christmas, ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  [donald, trump, just, couldn, t, wish, all, am...    News   \n",
       "1  [house, intelligence, committee, chairman, dev...    News   \n",
       "2  [on, friday, it, was, revealed, that, former, ...    News   \n",
       "3  [on, christmas, day, donald, trump, announced,...    News   \n",
       "4  [pope, francis, used, his, annual, christmas, ...    News   \n",
       "\n",
       "                date  label  \n",
       "0  December 31, 2017      0  \n",
       "1  December 31, 2017      0  \n",
       "2  December 30, 2017      0  \n",
       "3  December 29, 2017      0  \n",
       "4  December 25, 2017      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocess and tokenize dataset\n",
    "fake_df['label'] = 0\n",
    "true_df['label'] = 1\n",
    "news_df = pd.concat([fake_df, true_df])\n",
    "news_df['text'] = news_df['text'].str.lower()\n",
    "news_df['text'] = news_df['text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "news_df['text'] = news_df['text'].apply(lambda x: word_tokenize(x))\n",
    "news_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Word Extraction using Yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the YAKE keyword extractor\n",
    "# custom_kw_extractor = yake.KeywordExtractor(lan=\"en\", n=3, dedupLim=0.9, top=5, features=None)\n",
    "# # Extract the top 5 keywords for each news article\n",
    "# top_5_keywords = []\n",
    "# for i in range(news_df.shape[0]):\n",
    "#     # Extract the keywords for the current news article\n",
    "#     keywords = custom_kw_extractor.extract_keywords(' '.join([str(token) if isinstance(token, list) else token for token in news_df['text'][i]]))\n",
    "#     #keywords = custom_kw_extractor.extract_keywords(' '.join(map(str, news_df['text'][i])))\n",
    "#     #keywords = custom_kw_extractor.extract_keywords(' '.join(news_df['text'][i]))\n",
    "#     top_keywords = [keyword[0] for keyword in keywords]\n",
    "#     top_5_keywords.append(top_keywords)\n",
    "\n",
    "# # Add the top 5 keywords to the dataframe\n",
    "# news_df['top_5_keywords'] = top_5_keywords\n",
    "\n",
    "# # Print the top 5 keywords for the first news article\n",
    "# print(news_df['top_5_keywords'][0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAR algorithm (Context Analysis for Retrieval) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using CAR Method:  43.00859726491158\n",
      "Confusion Matrix: \n",
      "[[18250  5231]\n",
      " [20357  1060]]\n"
     ]
    }
   ],
   "source": [
    "# Define the keywords for each class (true and fake)\n",
    "true_keywords = ['true', 'fact', 'accurate', 'authentic']\n",
    "fake_keywords = ['fake', 'false', 'untrue', 'misleading']\n",
    "\n",
    "# Initialize the labels list\n",
    "labels = []\n",
    "\n",
    "# Loop through each news article\n",
    "for article in news_df['text']:\n",
    "    # Count the number of occurrences of each keyword in the article\n",
    "    true_count = sum(article.count(keyword) for keyword in true_keywords)\n",
    "    fake_count = sum(article.count(keyword) for keyword in fake_keywords)\n",
    "    \n",
    "    # Compare the counts to determine the label\n",
    "    if true_count > fake_count:\n",
    "        labels.append(1) # true\n",
    "    else:\n",
    "        labels.append(0) # fake\n",
    "\n",
    "car_algo_news_df = news_df\n",
    "car_algo_news_df['prediction'] = labels\n",
    "\n",
    "# calculate accuracy\n",
    "count = 0\n",
    "correct = 0\n",
    "for label in car_algo_news_df['label']:\n",
    "    if label == labels[count]:\n",
    "        correct += 1\n",
    "    count += 1\n",
    "print(\"Accuracy using CAR Method: \", correct/(len(labels)) * 100)\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(car_algo_news_df['label'], car_algo_news_df['prediction'])\n",
    "# Display the confusion matrix\n",
    "print(\"Confusion Matrix: \")\n",
    "print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of tokens back into a string\n",
    "news_df = pd.concat([fake_df, true_df])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(news_df['text'], news_df['label'], stratify=news_df['label'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Vectorize the text data using the CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=2)\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Multinomial Naive Bayes model\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_counts, y_train)\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = nb_classifier.predict(X_test_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "Precision: 0.95\n",
      "Recall: 0.96\n",
      "F1-score: 0.95\n",
      "Confusion Matrix: \n",
      "[[6702  343]\n",
      " [ 286 6139]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "# count = 0\n",
    "# correct = 0\n",
    "# # y_test.head()\n",
    "# for label in y_test:\n",
    "#     if label == y_pred[count]:\n",
    "#         correct += 1\n",
    "#     count += 1\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# Calculate the precision of the model\n",
    "precision = precision_score(y_test, y_pred)\n",
    "# Calculate the recall of the model\n",
    "recall = recall_score(y_test, y_pred)\n",
    "# Calculate the F1-score of the model\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "print(\"Confusion Matrix: \")\n",
    "print(cm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
